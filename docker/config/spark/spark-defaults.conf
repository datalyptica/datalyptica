# Spark Configuration File
# This file contains the configuration for Apache Spark with Iceberg Nessie catalog

# Spark Core Configuration
spark.master                     spark://shudl-spark-master:7077
spark.driver.memory              2g
spark.driver.maxResultSize       1g
spark.executor.memory            2g
spark.executor.cores             2
spark.executor.instances         2
spark.dynamicAllocation.enabled  false
spark.serializer                org.apache.spark.serializer.KryoSerializer
spark.sql.adaptive.enabled       true
spark.sql.adaptive.coalescePartitions.enabled true
spark.sql.adaptive.skewJoin.enabled true

# Spark SQL Configuration with Iceberg Nessie Catalog (matches working Trino config)
spark.sql.extensions             org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
spark.sql.catalog.iceberg        org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.iceberg.catalog-impl org.apache.iceberg.nessie.NessieCatalog
spark.sql.catalog.iceberg.uri    http://nessie:19120/api/v2
spark.sql.catalog.iceberg.ref    main
spark.sql.catalog.iceberg.warehouse s3://lakehouse/
spark.sql.catalog.iceberg.io-impl org.apache.iceberg.aws.s3.S3FileIO
spark.sql.catalog.iceberg.s3.endpoint http://minio:9000
spark.sql.catalog.iceberg.s3.access-key-id ${env:S3_ACCESS_KEY}
spark.sql.catalog.iceberg.s3.secret-access-key ${env:S3_SECRET_KEY}
spark.sql.catalog.iceberg.s3.path-style-access true
spark.sql.defaultCatalog         iceberg

# S3 Configuration (Hadoop S3A for legacy compatibility)
spark.hadoop.fs.s3a.endpoint    http://minio:9000
spark.hadoop.fs.s3a.access.key  ${env:S3_ACCESS_KEY}
spark.hadoop.fs.s3a.secret.key  ${env:S3_SECRET_KEY}
spark.hadoop.fs.s3a.path.style.access true
spark.hadoop.fs.s3a.impl        org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.aws.credentials.provider org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider

# Spark UI Configuration
spark.ui.port                    4040
spark.ui.retainedJobs            100
spark.ui.retainedStages          100
spark.ui.retainedTasks           100

# Spark History Server Configuration
spark.history.fs.logDirectory    s3a://lakehouse/spark-history
spark.history.fs.cleaner.enabled true
spark.history.fs.cleaner.interval 1d
spark.history.fs.cleaner.maxAge  7d

# Spark Event Log Configuration
spark.eventLog.enabled           false

# Spark Network Configuration
spark.network.timeout            800s
spark.executor.heartbeatInterval 60s
spark.rpc.askTimeout             800s
spark.rpc.lookupTimeout          800s

# Spark Shuffle Configuration
spark.sql.shuffle.partitions     200
spark.default.parallelism        200

# Spark Memory Configuration
spark.memory.fraction            0.8
spark.memory.storageFraction     0.3
spark.memory.offHeap.enabled     false
spark.memory.offHeap.size        0

# Spark Serialization Configuration
spark.serializer                org.apache.spark.serializer.KryoSerializer
spark.kryoserializer.buffer.max  2047m
spark.kryo.registrationRequired   false

# Spark Logging Configuration (disabled for now)
# spark.eventLog.enabled           true
# spark.eventLog.dir               s3a://lakehouse/spark-events
# spark.eventLog.compress          true 