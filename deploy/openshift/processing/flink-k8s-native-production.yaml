---
# ==============================================================================
# Kubernetes-Native Flink Deployment for Datalyptica Platform
# ==============================================================================
# Architecture: Flink Native Kubernetes with Application Mode
# - JobManager runs as a deployment for job orchestration
# - TaskManagers are dynamically allocated by JobManager
# - Integrates with Kafka, Iceberg, Nessie catalog, and MinIO storage
# ==============================================================================

---
# Namespace for Datalyptica Platform
apiVersion: v1
kind: Namespace
metadata:
  name: datalyptica
  labels:
    app.kubernetes.io/part-of: datalyptica
    name: datalyptica

---
# ConfigMap: Flink Configuration for K8s Native Mode
apiVersion: v1
kind: ConfigMap
metadata:
  name: flink-k8s-config
  namespace: datalyptica
  labels:
    app.kubernetes.io/name: flink
    app.kubernetes.io/component: config
    app.kubernetes.io/part-of: datalyptica
    datalyptica.io/tier: streaming
data:
  flink-conf.yaml: |
    # ============================================================================
    # Flink Kubernetes Native Configuration
    # ============================================================================
    
    # Kubernetes Cluster Configuration
    kubernetes.cluster-id: datalyptica-flink
    kubernetes.namespace: datalyptica
    kubernetes.service-account: flink
    kubernetes.container.image: image-registry.openshift-image-registry.svc:5000/datalyptica/flink-connectors:2.1.0
    kubernetes.container.image.pull-policy: Always
    
    # JobManager Configuration
    jobmanager.rpc.address: flink-jobmanager
    jobmanager.rpc.port: 6123
    jobmanager.bind-host: 0.0.0.0
    jobmanager.memory.process.size: 2048m
    jobmanager.memory.flink.size: 1536m
    jobmanager.memory.jvm-metaspace.size: 256m
    jobmanager.memory.jvm-overhead.min: 256m
    jobmanager.memory.jvm-overhead.max: 512m
    
    # TaskManager Configuration
    taskmanager.bind-host: 0.0.0.0
    taskmanager.host: 0.0.0.0
    taskmanager.rpc.port: 6122
    taskmanager.memory.process.size: 4096m
    taskmanager.memory.flink.size: 3072m
    taskmanager.memory.framework.heap.size: 128m
    taskmanager.memory.task.heap.size: 2048m
    taskmanager.memory.managed.fraction: 0.4
    taskmanager.memory.network.fraction: 0.1
    taskmanager.memory.jvm-metaspace.size: 256m
    taskmanager.memory.jvm-overhead.min: 512m
    taskmanager.memory.jvm-overhead.max: 768m
    taskmanager.numberOfTaskSlots: 4
    
    # Kubernetes Resource Configuration
    kubernetes.jobmanager.cpu: 2
    kubernetes.jobmanager.cpu.limit-factor: 2.0
    kubernetes.jobmanager.memory: "2048Mi"
    kubernetes.taskmanager.cpu: 2
    kubernetes.taskmanager.cpu.limit-factor: 2.0
    kubernetes.taskmanager.memory: "4096Mi"
    
    # Dynamic TaskManager Scaling
    taskmanager.replicas: 2
    kubernetes.taskmanager.replicas: 2
    
    # Pod Labels
    kubernetes.jobmanager.labels: app.kubernetes.io/name:flink,app.kubernetes.io/component:jobmanager,datalyptica.io/tier:streaming,app.kubernetes.io/part-of:datalyptica
    kubernetes.taskmanager.labels: app.kubernetes.io/name:flink,app.kubernetes.io/component:taskmanager,datalyptica.io/tier:streaming,app.kubernetes.io/part-of:datalyptica
    
    # Pod Annotations
    kubernetes.jobmanager.annotations: prometheus.io/scrape:true,prometheus.io/port:9249,prometheus.io/path:/metrics
    kubernetes.taskmanager.annotations: prometheus.io/scrape:true,prometheus.io/port:9249,prometheus.io/path:/metrics
    
    # Service Account
    kubernetes.jobmanager.service-account: flink
    
    # High Availability Configuration (Disabled for single JobManager)
    high-availability.type: kubernetes
    high-availability.storageDir: s3://lakehouse/flink/ha
    
    # State Backend Configuration - RocksDB with S3
    state.backend.type: rocksdb
    state.backend: rocksdb
    state.backend.incremental: true
    state.backend.rocksdb.timer-service.factory: rocksdb
    state.checkpoints.dir: s3://lakehouse/flink/checkpoints
    state.savepoints.dir: s3://lakehouse/flink/savepoints
    state.checkpoints.num-retained: 3
    
    # Checkpointing Configuration
    execution.checkpointing.interval: 60s
    execution.checkpointing.mode: EXACTLY_ONCE
    execution.checkpointing.min-pause: 30s
    execution.checkpointing.max-concurrent-checkpoints: 1
    execution.checkpointing.timeout: 10min
    execution.checkpointing.tolerable-failed-checkpoints: 5
    execution.checkpointing.externalized-checkpoint-retention: RETAIN_ON_CANCELLATION
    execution.checkpointing.checkpoints-after-tasks-finish.enabled: true
    
    # Restart Strategy Configuration
    restart-strategy.type: fixed-delay
    restart-strategy.fixed-delay.attempts: 5
    restart-strategy.fixed-delay.delay: 30s
    
    # REST API & Web UI Configuration
    rest.port: 8081
    rest.address: 0.0.0.0
    rest.bind-address: 0.0.0.0
    rest.bind-port: 8081
    web.submit.enable: true
    web.cancel.enable: true
    web.checkpoints.history: 20
    web.backpressure.refresh-interval: 10000
    
    # Parallelism Configuration
    parallelism.default: 4
    taskmanager.network.memory.fraction: 0.1
    taskmanager.network.memory.min: 64mb
    taskmanager.network.memory.max: 1gb
    
    # Table & SQL Configuration
    table.exec.resource.default-parallelism: 4
    table.exec.sink.not-null-enforcer: DROP
    table.exec.sink.upsert-materialize: AUTO
    table.optimizer.join-reorder-enabled: true
    table.optimizer.agg-phase-strategy: AUTO
    
    # S3/MinIO Configuration
    s3.endpoint: http://minio.datalyptica.svc.cluster.local:9000
    s3.path.style.access: true
    s3.connection.maximum: 100
    
    # Hadoop S3A Configuration
    fs.s3a.endpoint: http://minio.datalyptica.svc.cluster.local:9000
    fs.s3a.path.style.access: true
    fs.s3a.connection.ssl.enabled: false
    fs.s3a.impl: org.apache.hadoop.fs.s3a.S3AFileSystem
    fs.s3a.aws.credentials.provider: org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
    fs.s3a.connection.maximum: 100
    fs.s3a.threads.max: 50
    fs.s3a.fast.upload: true
    fs.s3a.block.size: 128M
    fs.s3a.multipart.size: 100M
    fs.s3a.fast.upload.buffer: disk
    
    # Metrics Configuration - Prometheus
    metrics.reporter.prom.factory.class: org.apache.flink.metrics.prometheus.PrometheusReporterFactory
    metrics.reporter.prom.port: 9249
    metrics.reporters: prom
    metrics.scope.jm: datalyptica.flink.jobmanager
    metrics.scope.tm: datalyptica.flink.taskmanager
    metrics.scope.job: datalyptica.flink.job
    metrics.scope.task: datalyptica.flink.task
    
    # Network Configuration
    taskmanager.network.request-backoff.initial: 100
    taskmanager.network.request-backoff.max: 10000
    taskmanager.network.retries: 3
    
    # I/O Configuration
    io.tmp.dirs: /tmp/flink-io
    taskmanager.data.port: 6121
    taskmanager.data.ssl.enabled: false
    
    # Classloading Configuration
    classloader.resolve-order: child-first
    classloader.parent-first-patterns.default: java.;scala.;org.apache.flink.;com.esotericsoftware.kryo;org.apache.hadoop;javax.annotation;org.slf4j;org.apache.log4j;org.apache.logging;org.apache.commons.logging;ch.qos.logback
    
    # Blob Server Configuration
    blob.server.port: 6124
    blob.service.cleanup.interval: 3600
    
    # Query Configuration
    queryable-state.enable: false
    
    # Slot Sharing Configuration
    cluster.evenly-spread-out-slots: true
    
  log4j-console.properties: |
    # Root Logger Configuration
    rootLogger.level = INFO
    rootLogger.appenderRef.console.ref = ConsoleAppender
    rootLogger.appenderRef.rolling.ref = RollingFileAppender
    
    # Console Appender
    appender.console.name = ConsoleAppender
    appender.console.type = CONSOLE
    appender.console.layout.type = PatternLayout
    appender.console.layout.pattern = %d{yyyy-MM-dd HH:mm:ss,SSS} %-5p [%t] %-60c %x - %m%n
    
    # Rolling File Appender
    appender.rolling.name = RollingFileAppender
    appender.rolling.type = RollingFile
    appender.rolling.fileName = /opt/flink/log/flink.log
    appender.rolling.filePattern = /opt/flink/log/flink-%d{yyyy-MM-dd}.log.gz
    appender.rolling.layout.type = PatternLayout
    appender.rolling.layout.pattern = %d{yyyy-MM-dd HH:mm:ss,SSS} %-5p [%t] %-60c %x - %m%n
    appender.rolling.policies.type = Policies
    appender.rolling.policies.time.type = TimeBasedTriggeringPolicy
    appender.rolling.policies.time.interval = 1
    appender.rolling.strategy.type = DefaultRolloverStrategy
    appender.rolling.strategy.max = 7
    
    # Suppress noisy loggers
    logger.akka.name = akka
    logger.akka.level = WARN
    
    logger.kafka.name = org.apache.kafka
    logger.kafka.level = INFO
    
    logger.hadoop.name = org.apache.hadoop
    logger.hadoop.level = WARN
    
    logger.zookeeper.name = org.apache.zookeeper
    logger.zookeeper.level = WARN
    
    logger.netty.name = org.jboss.netty
    logger.netty.level = WARN

---
# ServiceAccount for Flink
apiVersion: v1
kind: ServiceAccount
metadata:
  name: flink
  namespace: datalyptica
  labels:
    app.kubernetes.io/name: flink
    app.kubernetes.io/component: serviceaccount
    app.kubernetes.io/part-of: datalyptica

---
# Role: Flink Permissions
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: flink-role
  namespace: datalyptica
  labels:
    app.kubernetes.io/name: flink
    app.kubernetes.io/component: rbac
    app.kubernetes.io/part-of: datalyptica
rules:
# Pods - Create, list, watch, delete TaskManagers
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete", "deletecollection"]
# Pod logs - For debugging
- apiGroups: [""]
  resources: ["pods/log"]
  verbs: ["get", "list"]
# Services - For JobManager-TaskManager communication
- apiGroups: [""]
  resources: ["services"]
  verbs: ["get", "list", "create", "update", "patch", "delete"]
# ConfigMaps - For Flink configuration and HA
- apiGroups: [""]
  resources: ["configmaps"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
# Secrets - For accessing credentials
- apiGroups: [""]
  resources: ["secrets"]
  verbs: ["get", "list"]
# Deployments - For managing TaskManager deployments
- apiGroups: ["apps"]
  resources: ["deployments", "deployments/finalizers"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
# ReplicaSets - For TaskManager scaling
- apiGroups: ["apps"]
  resources: ["replicasets"]
  verbs: ["get", "list", "watch"]

---
# RoleBinding: Bind Flink Role to ServiceAccount
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: flink-rolebinding
  namespace: datalyptica
  labels:
    app.kubernetes.io/name: flink
    app.kubernetes.io/component: rbac
    app.kubernetes.io/part-of: datalyptica
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: flink-role
subjects:
- kind: ServiceAccount
  name: flink
  namespace: datalyptica

---
# Deployment: Flink JobManager
apiVersion: apps/v1
kind: Deployment
metadata:
  name: flink-jobmanager
  namespace: datalyptica
  labels:
    app.kubernetes.io/name: flink
    app.kubernetes.io/component: jobmanager
    app.kubernetes.io/part-of: datalyptica
    datalyptica.io/tier: streaming
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: flink
      app.kubernetes.io/component: jobmanager
  template:
    metadata:
      labels:
        app.kubernetes.io/name: flink
        app.kubernetes.io/component: jobmanager
        app.kubernetes.io/part-of: datalyptica
        datalyptica.io/tier: streaming
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9249"
        prometheus.io/path: "/metrics"
    spec:
      serviceAccountName: flink
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 1000
      containers:
      - name: jobmanager
        image: image-registry.openshift-image-registry.svc:5000/datalyptica/flink-connectors:2.1.0
        imagePullPolicy: Always
        command: ["/bin/bash", "-c"]
        args:
        - |
          set -e
          echo "Starting Flink JobManager..."
          echo "Flink version: $(flink --version)"
          $FLINK_HOME/bin/jobmanager.sh start-foreground
        ports:
        - name: rpc
          containerPort: 6123
          protocol: TCP
        - name: blob
          containerPort: 6124
          protocol: TCP
        - name: ui
          containerPort: 8081
          protocol: TCP
        - name: metrics
          containerPort: 9249
          protocol: TCP
        env:
        # AWS/S3 Credentials for MinIO
        - name: AWS_ACCESS_KEY_ID
          valueFrom:
            secretKeyRef:
              name: minio-credentials
              key: root-user
        - name: AWS_SECRET_ACCESS_KEY
          valueFrom:
            secretKeyRef:
              name: minio-credentials
              key: root-password
        # S3 Endpoint Configuration
        - name: S3_ENDPOINT
          value: "http://minio.datalyptica.svc.cluster.local:9000"
        - name: S3_PATH_STYLE_ACCESS
          value: "true"
        # Flink Configuration
        - name: FLINK_PROPERTIES
          value: |
            jobmanager.rpc.address: flink-jobmanager
            blob.server.port: 6124
            query.server.port: 6125
        # JVM Options
        - name: FLINK_JM_HEAP
          value: "1536m"
        volumeMounts:
        - name: flink-config
          mountPath: /opt/flink/conf/flink-conf.yaml
          subPath: flink-conf.yaml
        - name: flink-config
          mountPath: /opt/flink/conf/log4j-console.properties
          subPath: log4j-console.properties
        - name: flink-logs
          mountPath: /opt/flink/log
        resources:
          requests:
            memory: "2Gi"
            cpu: "2000m"
          limits:
            memory: "2560Mi"
            cpu: "4000m"
        livenessProbe:
          httpGet:
            path: /overview
            port: 8081
          initialDelaySeconds: 60
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 5
        readinessProbe:
          httpGet:
            path: /overview
            port: 8081
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
      volumes:
      - name: flink-config
        configMap:
          name: flink-k8s-config
      - name: flink-logs
        emptyDir: {}

---
# Deployment: Flink TaskManager
apiVersion: apps/v1
kind: Deployment
metadata:
  name: flink-taskmanager
  namespace: datalyptica
  labels:
    app.kubernetes.io/name: flink
    app.kubernetes.io/component: taskmanager
    app.kubernetes.io/part-of: datalyptica
    datalyptica.io/tier: streaming
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: flink
      app.kubernetes.io/component: taskmanager
  template:
    metadata:
      labels:
        app.kubernetes.io/name: flink
        app.kubernetes.io/component: taskmanager
        app.kubernetes.io/part-of: datalyptica
        datalyptica.io/tier: streaming
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9249"
        prometheus.io/path: "/metrics"
    spec:
      serviceAccountName: flink
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 1000
      containers:
      - name: taskmanager
        image: image-registry.openshift-image-registry.svc:5000/datalyptica/flink-connectors:2.1.0
        imagePullPolicy: Always
        command: ["/bin/bash", "-c"]
        args:
        - |
          set -e
          echo "Starting Flink TaskManager..."
          $FLINK_HOME/bin/taskmanager.sh start-foreground
        ports:
        - name: data
          containerPort: 6121
          protocol: TCP
        - name: rpc
          containerPort: 6122
          protocol: TCP
        - name: metrics
          containerPort: 9249
          protocol: TCP
        env:
        # AWS/S3 Credentials for MinIO
        - name: AWS_ACCESS_KEY_ID
          valueFrom:
            secretKeyRef:
              name: minio-credentials
              key: root-user
        - name: AWS_SECRET_ACCESS_KEY
          valueFrom:
            secretKeyRef:
              name: minio-credentials
              key: root-password
        # S3 Endpoint Configuration
        - name: S3_ENDPOINT
          value: "http://minio.datalyptica.svc.cluster.local:9000"
        - name: S3_PATH_STYLE_ACCESS
          value: "true"
        # Flink Configuration
        - name: FLINK_PROPERTIES
          value: |
            jobmanager.rpc.address: flink-jobmanager
            taskmanager.rpc.port: 6122
        # JVM Options
        - name: FLINK_TM_HEAP
          value: "3072m"
        volumeMounts:
        - name: flink-config
          mountPath: /opt/flink/conf/flink-conf.yaml
          subPath: flink-conf.yaml
        - name: flink-config
          mountPath: /opt/flink/conf/log4j-console.properties
          subPath: log4j-console.properties
        - name: flink-logs
          mountPath: /opt/flink/log
        - name: flink-tmp
          mountPath: /tmp/flink-io
        resources:
          requests:
            memory: "4Gi"
            cpu: "2000m"
          limits:
            memory: "4864Mi"
            cpu: "4000m"
        livenessProbe:
          tcpSocket:
            port: 6122
          initialDelaySeconds: 60
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 5
        readinessProbe:
          tcpSocket:
            port: 6122
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
      volumes:
      - name: flink-config
        configMap:
          name: flink-k8s-config
      - name: flink-logs
        emptyDir: {}
      - name: flink-tmp
        emptyDir: {}

---
# Service: Flink JobManager RPC
apiVersion: v1
kind: Service
metadata:
  name: flink-jobmanager
  namespace: datalyptica
  labels:
    app.kubernetes.io/name: flink
    app.kubernetes.io/component: jobmanager
    app.kubernetes.io/part-of: datalyptica
spec:
  type: ClusterIP
  selector:
    app.kubernetes.io/name: flink
    app.kubernetes.io/component: jobmanager
  ports:
  - name: rpc
    port: 6123
    targetPort: 6123
    protocol: TCP
  - name: blob
    port: 6124
    targetPort: 6124
    protocol: TCP
  - name: ui
    port: 8081
    targetPort: 8081
    protocol: TCP
  - name: metrics
    port: 9249
    targetPort: 9249
    protocol: TCP

---
# Service: Flink JobManager REST (for external access)
apiVersion: v1
kind: Service
metadata:
  name: flink-jobmanager-rest
  namespace: datalyptica
  labels:
    app.kubernetes.io/name: flink
    app.kubernetes.io/component: jobmanager
    app.kubernetes.io/part-of: datalyptica
spec:
  type: ClusterIP
  selector:
    app.kubernetes.io/name: flink
    app.kubernetes.io/component: jobmanager
  ports:
  - name: rest
    port: 8081
    targetPort: 8081
    protocol: TCP

---
# Service: Flink TaskManager (Headless for direct pod access)
apiVersion: v1
kind: Service
metadata:
  name: flink-taskmanager
  namespace: datalyptica
  labels:
    app.kubernetes.io/name: flink
    app.kubernetes.io/component: taskmanager
    app.kubernetes.io/part-of: datalyptica
spec:
  type: ClusterIP
  clusterIP: None
  selector:
    app.kubernetes.io/name: flink
    app.kubernetes.io/component: taskmanager
  ports:
  - name: data
    port: 6121
    targetPort: 6121
    protocol: TCP
  - name: rpc
    port: 6122
    targetPort: 6122
    protocol: TCP
  - name: metrics
    port: 9249
    targetPort: 9249
    protocol: TCP

---
# PodDisruptionBudget: Ensure availability during disruptions
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: flink-jobmanager-pdb
  namespace: datalyptica
  labels:
    app.kubernetes.io/name: flink
    app.kubernetes.io/component: jobmanager
    app.kubernetes.io/part-of: datalyptica
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: flink
      app.kubernetes.io/component: jobmanager

---
# PodDisruptionBudget: Ensure TaskManager availability during disruptions
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: flink-taskmanager-pdb
  namespace: datalyptica
  labels:
    app.kubernetes.io/name: flink
    app.kubernetes.io/component: taskmanager
    app.kubernetes.io/part-of: datalyptica
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: flink
      app.kubernetes.io/component: taskmanager
