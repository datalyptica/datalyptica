# Spark Configuration Template
# This file is processed at runtime to substitute environment variables
# Based on the working static configuration

# Spark Core Configuration
spark.master                     ${SPARK_MASTER_URL}
spark.driver.memory              ${SPARK_DRIVER_MEMORY}
spark.driver.maxResultSize       ${SPARK_DRIVER_MAX_RESULT_SIZE}
spark.executor.memory            ${SPARK_EXECUTOR_MEMORY}
spark.executor.cores             ${SPARK_EXECUTOR_CORES}
spark.executor.instances         ${SPARK_EXECUTOR_INSTANCES}
spark.dynamicAllocation.enabled  ${SPARK_DYNAMIC_ALLOCATION_ENABLED}
spark.serializer                ${SPARK_SERIALIZER}
spark.sql.adaptive.enabled       ${SPARK_SQL_ADAPTIVE_ENABLED}
spark.sql.adaptive.coalescePartitions.enabled ${SPARK_SQL_ADAPTIVE_COALESCE_PARTITIONS_ENABLED}
spark.sql.adaptive.skewJoin.enabled ${SPARK_SQL_ADAPTIVE_SKEW_JOIN_ENABLED}

# Spark SQL Configuration with Iceberg Nessie Catalog (matches working Trino config)
spark.sql.extensions             org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
spark.sql.catalog.iceberg        org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.iceberg.catalog-impl org.apache.iceberg.nessie.NessieCatalog
spark.sql.catalog.iceberg.uri    ${SPARK_ICEBERG_URI}
spark.sql.catalog.iceberg.ref    main
spark.sql.catalog.iceberg.warehouse ${SPARK_ICEBERG_WAREHOUSE}
spark.sql.catalog.iceberg.io-impl ${SPARK_ICEBERG_IO_IMPL}
spark.sql.catalog.iceberg.s3.endpoint ${S3_ENDPOINT}
spark.sql.catalog.iceberg.s3.access-key-id ${S3_ACCESS_KEY}
spark.sql.catalog.iceberg.s3.secret-access-key ${S3_SECRET_KEY}
spark.sql.catalog.iceberg.s3.path-style-access ${S3_PATH_STYLE_ACCESS}
spark.sql.catalog.iceberg.s3.region us-east-1

# S3 Configuration (Hadoop S3A for legacy compatibility)
spark.hadoop.fs.s3a.endpoint    ${S3_ENDPOINT}
spark.hadoop.fs.s3a.access.key  ${S3_ACCESS_KEY}
spark.hadoop.fs.s3a.secret.key  ${S3_SECRET_KEY}
spark.hadoop.fs.s3a.path.style.access ${S3_PATH_STYLE_ACCESS}
spark.hadoop.fs.s3a.region      us-east-1
spark.hadoop.fs.s3a.impl        org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.aws.credentials.provider org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider

# Spark UI Configuration
spark.ui.port                    ${SPARK_UI_PORT}
spark.ui.retainedJobs            100
spark.ui.retainedStages          100
spark.ui.retainedTasks           100

# Spark History Server Configuration
spark.history.fs.logDirectory    ${SPARK_ICEBERG_WAREHOUSE}/spark-history
spark.history.fs.cleaner.enabled true
spark.history.fs.cleaner.interval 1d
spark.history.fs.cleaner.maxAge  7d

# Spark Event Log Configuration
spark.eventLog.enabled           false

# Spark Network Configuration
spark.network.timeout            800s
spark.executor.heartbeatInterval 60s
spark.rpc.askTimeout             800s
spark.rpc.lookupTimeout          800s

# Spark Shuffle Configuration
spark.sql.shuffle.partitions     200
spark.default.parallelism        200

# Spark Memory Configuration
spark.memory.fraction            0.8
spark.memory.storageFraction     0.3
spark.memory.offHeap.enabled     false
spark.memory.offHeap.size        0

# Spark Serialization Configuration
spark.serializer                org.apache.spark.serializer.KryoSerializer
spark.kryoserializer.buffer.max  2047m
spark.kryo.registrationRequired   false
