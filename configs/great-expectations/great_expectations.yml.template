# Great Expectations Configuration Template
# This file will be processed by entrypoint.sh using envsubst

config_version: 3.0

datasources:
  postgres_datasource:
    class_name: Datasource
    execution_engine:
      class_name: SqlAlchemyExecutionEngine
      connection_string: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}
    data_connectors:
      default_inferred_data_connector_name:
        class_name: InferredAssetSqlDataConnector
        include_schema_name: true
      default_runtime_data_connector_name:
        class_name: RuntimeDataConnector
        batch_identifiers:
          - default_identifier_name

  trino_datasource:
    class_name: Datasource
    execution_engine:
      class_name: SqlAlchemyExecutionEngine
      connection_string: trino://${TRINO_HOST:-trino}:${TRINO_PORT:-8080}/${TRINO_CATALOG:-iceberg}
    data_connectors:
      default_inferred_data_connector_name:
        class_name: InferredAssetSqlDataConnector
        include_schema_name: true
      default_runtime_data_connector_name:
        class_name: RuntimeDataConnector
        batch_identifiers:
          - default_identifier_name

  s3_pandas_datasource:
    class_name: Datasource
    execution_engine:
      class_name: PandasExecutionEngine
    data_connectors:
      s3_data_connector:
        class_name: ConfiguredAssetS3DataConnector
        bucket: ${S3_BUCKET:-lakehouse}
        prefix: warehouse/
        boto3_options:
          endpoint_url: ${S3_ENDPOINT}
        default_regex:
          pattern: (.*)\.parquet
          group_names:
            - data_asset_name

  spark_datasource:
    class_name: Datasource
    execution_engine:
      class_name: SparkDFExecutionEngine
      spark_config:
        spark.sql.catalog.iceberg: org.apache.iceberg.spark.SparkCatalog
        spark.sql.catalog.iceberg.catalog-impl: org.apache.iceberg.nessie.NessieCatalog
        spark.sql.catalog.iceberg.uri: ${NESSIE_URI}
        spark.sql.catalog.iceberg.warehouse: ${NESSIE_WAREHOUSE:-s3://lakehouse/warehouse}
        spark.sql.catalog.iceberg.s3.endpoint: ${S3_ENDPOINT}
        spark.sql.catalog.iceberg.s3.access-key-id: ${S3_ACCESS_KEY}
        spark.sql.catalog.iceberg.s3.secret-access-key: ${S3_SECRET_KEY}
        spark.sql.catalog.iceberg.s3.path-style-access: true
    data_connectors:
      default_runtime_data_connector_name:
        class_name: RuntimeDataConnector
        batch_identifiers:
          - default_identifier_name

stores:
  expectations_store:
    class_name: ExpectationsStore
    store_backend:
      class_name: TupleFilesystemStoreBackend
      base_directory: expectations/

  validations_store:
    class_name: ValidationsStore
    store_backend:
      class_name: TupleFilesystemStoreBackend
      base_directory: uncommitted/validations/

  evaluation_parameter_store:
    class_name: EvaluationParameterStore

  checkpoint_store:
    class_name: CheckpointStore
    store_backend:
      class_name: TupleFilesystemStoreBackend
      base_directory: checkpoints/

  profiler_store:
    class_name: ProfilerStore
    store_backend:
      class_name: TupleFilesystemStoreBackend
      base_directory: profilers/

expectations_store_name: expectations_store
validations_store_name: validations_store
evaluation_parameter_store_name: evaluation_parameter_store
checkpoint_store_name: checkpoint_store

data_docs_sites:
  local_site:
    class_name: SiteBuilder
    show_how_to_buttons: true
    store_backend:
      class_name: TupleFilesystemStoreBackend
      base_directory: uncommitted/data_docs/local_site/
    site_index_builder:
      class_name: DefaultSiteIndexBuilder

  s3_site:
    class_name: SiteBuilder
    show_how_to_buttons: true
    store_backend:
      class_name: TupleS3StoreBackend
      bucket: ${S3_BUCKET:-lakehouse}
      prefix: data_docs/
      boto3_options:
        endpoint_url: ${S3_ENDPOINT}
    site_index_builder:
      class_name: DefaultSiteIndexBuilder

analytics_enabled: false
